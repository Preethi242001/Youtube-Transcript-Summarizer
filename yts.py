#-*- coding: utf-8 -*-

"""Youtube_summ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1roDw6nSishryhzyuNe_W-pphYwr7EWWV
"""
import sys
import pandas as pd
from youtube_transcript_api import YouTubeTranscriptApi as YTapi
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from datetime import datetime

#first install fpdf using command: pip install fpdf2
from fpdf import FPDF

def print_current_time():
    now = datetime.now()
    current_time = now.strftime("%H:%M:%S")
    print("Current Time =", current_time)
    print("---------------------------------------------")
    return
    
#------------------------------------------------
def videoID(link):
    video_id = link.split("=")[1]
    return video_id
    
#------------------------------------------------
    
def GetTranscript(video_id):
    try:
        transcript = YTapi.get_transcript(video_id)
        FinalTranscript = ' '.join([i['text'] for i in transcript])
        #print("FinalTranscript=", FinalTranscript)
        return FinalTranscript
    except Exception as e:
        print(e)
        return None
    
#------------------------------------------------

"""
--------------------------------------------------
Function to summarize the text(transcript)
--------------------------------------------------
"""
def summarize(tokenizer, model, text):
    
 
    
    #print("In function summarize ,transcript  = ", text)
    
    inputs = tokenizer(text, 
                    max_length=1024, 
                    truncation=True,
                    return_tensors="pt")
  
    summary_ids = model.generate(inputs["input_ids"], max_new_tokens = 512)
    summary = tokenizer.batch_decode(summary_ids, 
                                  skip_special_tokens=True, 
                                  clean_up_tokenization_spaces=False)
    return summary
    
#------------------------------------------------    
def convertTextToPDF(text_file_name):
    text_file_name_with_extn = text_file_name + ".txt"
    # open the text file in read mode
    print("Converting the File: ", text_file_name_with_extn, "to PDF...")
    print("<br>")
    input_file = open(text_file_name_with_extn, "r")

    pdf = FPDF()
    pdf.add_page()
    pdf.set_font('helvetica', size=12)
    pdf.set_char_spacing(spacing=0)



    # insert the texts in pdf
    for x in input_file:
        pdf.multi_cell(0, 5, txt = x, new_x="LMARGIN", new_y="NEXT", align='L')
        
    pdf_file_name_with_extn = text_file_name + ".pdf" 

    #pdf.output('example1.pdf', 'F')    
    pdf.output(pdf_file_name_with_extn, 'F')
    print("File: ", pdf_file_name_with_extn, " generated successfully...")
    print("<br>")
   
    input_file.close()
    return
    
#####################################################
# main driver code

print("python program execution started ....")
print_current_time()

trans_file = open("transcript.txt", "w")
sumry_file = open("summary.txt", "w") 

    
# argument-1
#youtube_link = "https://www.youtube.com/watch?v=A4OmtyaBHFE"
youtube_link = sys.argv[1]
print("youtube_link=", youtube_link)

# argument-2
#option given in html page (chrome browser)

youtube_link_lang_opt = sys.argv[2]
print("youtube_link_lang_opt=", youtube_link_lang_opt)

# argument-3
#tamil, telugu, hindi not getting displayed in chrome browser as of now
# string TRUE or FALSE

"""
tamil, telugh,hindi fonts are displayed in GOOGLE COLAB, IDLE Environment    
and these fonts are not displayed in chrome browser as of now.
In chrome browser output is getting stopped partially.
Managing this with variable grphcs_font_display_option
"""

grphcs_font_display_option = sys.argv[3]
#print("grphcs_font_display option = ", grphcs_font_display_option)



id = videoID(youtube_link)
#id
print("video id=", id)




transcript_en = GetTranscript(id)
print("transcript_en = ", transcript_en)
print("transcript_en = ", transcript_en, file = trans_file)
print("length of transcript_en = ", len(transcript_en) )
print("---------------------------------------------")



transcript_list  = YTapi.list_transcripts(id)
#print("transcript_list =", transcript_list)


for transcript in transcript_list:
    #print("for loop1: iteration")
    ln = transcript.language
    #print("transcript.language = ", ln)
    check = transcript.is_translatable 
    #print("transcript.is_translatable = ", check)    
    #print(ln, check)


for transcript in transcript_list:
    #print("for loop2: iteration")
    available_ln = transcript.translation_languages
    #print("transcript.translation_languages = ", available_ln)
#print(available_ln, end = " ")
#print()

"""
tamil, telugh,hindi fonts are displayed in GOOGLE COLAB, IDLE Environment    
and these fonts are not displayed in chrome browser as of now.
In chrome browser output is getting stopped partially.
So below logic to avoid printing these fonts in browser
"""
if (grphcs_font_display_option == "TRUE" ):

    transcript_ta = ' '.join([i['text'] for i in transcript.translate('ta').fetch()])
    print("transcript_ta", transcript_ta)
    print("length of transcript_ta = ", len(transcript_ta) )
    print("---------------------------------------------")

    transcript_telugu = ' '.join([i['text'] for i in transcript.translate('te').fetch()])
    print("transcript_telugu", transcript_telugu)
    print("length of transcript_telugu = ", len(transcript_telugu) )
    print("---------------------------------------------")

    transcript_hindi = ' '.join([i['text'] for i in transcript.translate('hi').fetch()])
    print("transcript_hindi", transcript_hindi)
    print("length of transcript_hindi = ", len(transcript_hindi) )
    print("---------------------------------------------")

transcript_spanish = ' '.join([i['text'] for i in transcript.translate('es').fetch()])
print("transcript_spanish", transcript_spanish)
print("length of transcript_spanish = ", len(transcript_spanish) )
print("---------------------------------------------")


transcript_french = ' '.join([i['text'] for i in transcript.translate('fr').fetch()])
print("transcript_french", transcript_french)
print("length of transcript_french = ", len(transcript_french) )
print("---------------------------------------------")

print("Transcript details are collected .... ")

#------summarization logic below ----------------------------------

print("Summary process execution started .... ")
print_current_time()

checkpoint1 = "google/pegasus-large"
checkpoint2 = "csebuetnlp/mT5_multilingual_XLSum"
checkpoint3 = "sshleifer/distilbart-cnn-12-6"
checkpoint4 = "ai4bharat/IndicBART"

tokenizer1 = AutoTokenizer.from_pretrained(checkpoint1)
model1 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint1)

tokenizer2 = AutoTokenizer.from_pretrained(checkpoint2)
model2 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint2)

tokenizer3 = AutoTokenizer.from_pretrained(checkpoint3)
model3 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint3)

tokenizer4 = AutoTokenizer.from_pretrained(checkpoint4)
model4 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint4)

#model1
pegasus = summarize(tokenizer1, model1, transcript_en)

print("summary generated based on model1: pegasus ....")
print("model1:pegasus ....",file = sumry_file)
print_current_time()
print(pegasus[0],file = sumry_file)
print("--------------------------",file = sumry_file)


#model2
#mt5 = summarize(tokenizer2, model2, transcript_ta)
mt5 = summarize(tokenizer2, model2, transcript_en)

print("summary generated based on model2: mT5 ....")
print("model2: mT5....",file = sumry_file)
print_current_time()
print(mt5[0],file = sumry_file)
print("--------------------------",file = sumry_file)


#model3
bart = summarize(tokenizer3, model3, transcript_en)

print("summary generated based on model3: distilbart-cnn ....")

print("model3: distilbart-cnn....",file = sumry_file)

print_current_time()
print(bart[0],file = sumry_file)
print("--------------------------",file = sumry_file)

#model4
#HiBart_hindi = summarize(tokenizer4, model4, transcript_hindi)
HiBart = summarize(tokenizer4, model4, transcript_en)

print("summary generated based on model4: ai4bharat ....")
print("model4: ai4bharat ....",file = sumry_file)

print_current_time()
#print(HiBart_hindi[0])
print(HiBart[0],file = sumry_file)
print("--------------------------",file = sumry_file)


trans_file.close()
sumry_file.close()

#=============================================

print("PDF Download process started....")
print_current_time()

# convert transcript.txt
convertTextToPDF("transcript")

# convert summary.txt
convertTextToPDF("summary")

print("PDF Download process completed....")
print_current_time()


print("python program execution completed....")
print_current_time()


